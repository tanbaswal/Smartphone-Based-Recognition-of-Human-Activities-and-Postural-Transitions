# -*- coding: utf-8 -*-
"""HUMAN ACTIVITY RECOGNITION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xt-O94rYfSeyCt78j-XWeqXhdGEWqBxw
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import numpy as np
import pylab as pl
import pandas as pd
import matplotlib.pyplot as plt 
# %matplotlib inline

from sklearn.utils import shuffle
from sklearn.svm import SVC
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.model_selection import cross_val_score, GridSearchCV

#LOADING DATASET
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')
print('Shape Train:\t{}'.format(train_df.shape))
print('Shape Test:\t{}\n'.format(test_df.shape))
train_df.head()

# INFORMATION ABOUT LABELS
train_outcome = pd.crosstab(index=train_df["Activity"],  # Make a crosstab
                              columns="count")      # Name the count column

train_outcome.head(6)

# PLOTTING DATA
temp = train_df["Activity"].value_counts()
df = pd.DataFrame({'labels': temp.index,
                   'values': temp.values
                  })
labels = df['labels']
sizes = df['values']
colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','cyan','lightpink']
patches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, pctdistance=1.1, labeldistance=1.2)
plt.legend(patches, labels, loc="best")
plt.axis('equal')
plt.tight_layout()
plt.show()

# MODELLING 
X_train = pd.DataFrame(train_df.drop(['Activity','subject'],axis=1))
Y_train_label = train_df.Activity.values.astype(object)
X_test = pd.DataFrame(test_df.drop(['Activity','subject'],axis=1))
Y_test_label = test_df.Activity.values.astype(object)

#ENCODING 
encoder = preprocessing.LabelEncoder()
encoder.fit(Y_train_label)
Y_train = encoder.transform(Y_train_label)
encoder.fit(Y_test_label)
Y_test = encoder.transform(Y_test_label)

# SCALING
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# CHOOSING THE BEST KERNEL FOR THE MODEL
params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],
                     'C': [1, 10, 100, 1000]},
                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]
svm_model = GridSearchCV(SVC(), params_grid, cv=5)
svm_model.fit(X_train_scaled, Y_train)      

print('Best score for training data:', svm_model.best_score_,"\n") 
print('Best C:',svm_model.best_estimator_.C,"\n") 
print('Best Kernel:',svm_model.best_estimator_.kernel,"\n")
print('Best Gamma:',svm_model.best_estimator_.gamma,"\n")

# CONFUSION MATRIX
final_model = svm_model.best_estimator_
Y_pred = final_model.predict(X_test_scaled)
Y_pred_label = list(encoder.inverse_transform(Y_pred))

print(confusion_matrix(Y_test_label,Y_pred_label))
print("\n")
print(classification_report(Y_test_label,Y_pred_label))

print("Training set score for SVM: %f" % final_model.score(X_train_scaled , Y_train))
print("Testing  set score for SVM: %f" % final_model.score(X_test_scaled  , Y_test ))

svm_model.score